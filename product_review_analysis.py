# -*- coding: utf-8 -*-
"""Product Review Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ap3f5d8JVLF1rAyRRBETSGzEjWWRyNWq
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plot
import seaborn as sns
import nltk
import nltk.corpus

from google.colab import drive
drive.mount('/content/drive')

df =  pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Product Review Analysis/Mobile Reviews.csv')

df.head()

df = df.drop(columns = df.columns[0])

df

df.head()

"""# ***Data Cleaning***"""

df["Review-Title"].isna().sum()

df.dropna(subset=['Review-Title'], axis=0, inplace=True)
df["Review-Title"].isna().sum()

df["rating"].isna().sum()

df['rating'].unique()

df["Review-Body"].isna().sum()

df.dropna(subset=['Review-Body'], axis=0, inplace=True)
df["Review-Body"].isna().sum()

df["Product Name"].isna().sum()

df['rating_number'] = [int(i[:1]) for i in df['rating']]
df.drop('rating', axis=1, inplace=True)
df

df['Product Name'].unique()

"""There are eight different types of mobiles."""

!pip install vaderSentiment

from wordcloud import WordCloud
from collections import Counter
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
import re
import string
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import pos_tag
nltk.download('stopwords')
from nltk.corpus import stopwords
nltk.download('wordnet')
from nltk.corpus import wordnet
nltk.download('omw-1.4')
nltk.download('averaged_perceptron_tagger')

df_best_reviews = df.loc[(~df['Review-Body'].isna()) & (df['rating_number']==5)]
df_worst_reviews = df.loc[(~df['Review-Body'].isna()) & (df['rating_number']==1)]

def generate_wordcloud(text):
    """
    Generate word cloud images
    """
    wc = WordCloud(collocations=False, 
                   background_color="black",
                   max_words=200).generate(text)
    
    # set the figure size
    plot.figure(figsize=[15,10])

    # plot the wordcloud
    plot.imshow(wc, interpolation="bilinear")

    # remove plot axes
    plot.axis("off")

text_best_reviews = " ".join(df_best_reviews['Review-Body'])
print('Word cloud: 5-star reviews:')
generate_wordcloud(text_best_reviews)

text_worst_reviews = " ".join(df_worst_reviews['Review-Body'])
print('Word cloud: 1-star reviews:')
generate_wordcloud(text_worst_reviews)

ax1 = df['rating_number'].plot(kind='hist', 
                          color='blue', 
                          grid=False, 
                          bins=[1,1.5,2,2.5,3,3.5,4,4.5,5,5.5], 
                          title='Review Rating Distribution',
                          figsize=(15,10))
ax1.set_xlabel("Rating")
ax1.set_ylabel("Count")
ax1.set_xticks([1,2,3,4,5], minor=False)

# set font size  
plot.rcParams['font.size'] = '10'

"""As seen from above chart, in this data we have more 5 star rated reviews, followed by 1 star & 4 star."""

df['Review-Body'] = df['Review-Body'].astype(str)
df['review'] = df['Review-Body'].str.lower()
df

def remove_urls(text):
    url_pattern = re.compile(r'https?://\S+|www\.\S+')
    return url_pattern.sub(r'', text)

df['review'] = df['review'].apply(lambda text: remove_urls(text))
df.head()

PUNCT_TO_REMOVE = string.punctuation
def remove_punctuation(text):
    """custom function to remove the punctuation"""
    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))

df['review_wo_punct'] = df['review'].apply(lambda text: remove_punctuation(text))
df.head()

from nltk.corpus import stopwords
", ".join(stopwords.words('english'))

STOPWORDS = set(stopwords.words('english'))
def remove_stopwords(text):
    """custom function to remove the stopwords"""
    return " ".join([word for word in str(text).split() if word not in STOPWORDS])

df['review_wo_stop'] = df['review_wo_punct'].apply(lambda text: remove_stopwords(text))
df.head()

cnt = Counter()
for text in df['review_wo_stop'].values:
    for word in text.split():
        cnt[word] += 1

cnt.most_common(20)

df['review_wo_stop'] = df['review_wo_stop'].str.replace('\d+', '')
df.head()

df.drop(['Review-Body','review','review_wo_punct'], axis=1, inplace=True)
df.head()

# POS tagger dictionary
pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}

def token_stop_pos(text):
    tags = pos_tag(word_tokenize(text))
    newlist = []
    for word, tag in tags:
        if word.lower() not in set(stopwords.words('english')):
            newlist.append(tuple([word, pos_dict.get(tag[0])]))
    return newlist

Y = df['review_wo_stop']
df['POS_tagged'] = Y.apply(token_stop_pos)
df.head()

wordnet_lemmatizer = WordNetLemmatizer()

def lemmatize(pos_data):
    lemma_rew = " "
    for word, pos in pos_data:
        if not pos:
            lemma = word
            lemma_rew = lemma_rew + " " + lemma
        else:
            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)
            lemma_rew = lemma_rew + " " + lemma
    return lemma_rew
    
df['Lemma'] = df['POS_tagged'].apply(lemmatize)
df.head()

"""# ***Using Vader for analysing sentiment of the cleaned reviews***"""

sent_analyser = SentimentIntensityAnalyzer()

# function to calculate polarity
def getPolarity(text):
    return sent_analyser.polarity_scores(text)["compound"]

# function to analyze the reviews
def analysis(score):
    if score < 0:
        return 'Negative'
    elif score == 0:
        return 'Neutral'
    else:
        return 'Positive'

df['Polarity'] = df['Lemma'].apply(getPolarity)
df['Sentiment'] = df['Polarity'].apply(analysis)
df.drop(['POS_tagged','Lemma'], axis=1, inplace=True)
df.head()

sent_counts = df['Sentiment'].value_counts()

plot.figure(figsize=(10,7))
plot.pie(sent_counts.values, labels=sent_counts.index, explode=(0,0,0.25), autopct='%1.1f%%', shadow=False)
plot.legend();

"""As seen from above chart, we see 65% Positive Sentiments, 19.3% Negative Sentiments & 15.7% Neutral Sentiments."""

sent_counts

phone_df = df[['Product Name','Sentiment']]
phone_df

phone_df.groupby(['Product Name','Sentiment'])['Sentiment'].count()

"""From above groupby table, we see:

Positive Sentiments Top 3:

a) Redmi 9 Activ (Carbon Black, 4GB RAM, 64GB Storage) - 3005

b) OPPO A31 (Mystery Black, 6GB RAM, 128GB Storage) - 2966

c) OnePlus Nord CE 2 5G (Gray Mirror, 8GB RAM, 128GB Storage) - 2308

Neutral Sentiments Top 3:

a) OPPO A31 (Mystery Black, 6GB RAM, 128GB Storage) - 718

b) Redmi 10 Prime (Bifrost Blue 4GB RAM 64GB ROM - 675

c) OnePlus Nord CE 2 5G (Gray Mirror, 8GB RAM, 128GB Storage) - 571

Negative Sentiments Top 3:

a) Redmi 9 Activ (Carbon Black, 4GB RAM, 64GB Storage) - 926

b) Redmi 10 Prime (Bifrost Blue 4GB RAM 64GB ROM - 859

c) Redmi Note 11 (Space Black, 4GB RAM, 64GB Storage) - 613
"""